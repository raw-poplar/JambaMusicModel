
**推理 (生成) 过程**

训练完成后，模型可以用来生成新的音频编码 `s_generated`，然后用 DAC 解码。这是一个 **自回归 (auto-regressive)** 的过程：

1.  **起始输入:** 提供一个初始输入给 Mamba。这可以是一个特殊的 "start-of-sequence" (SOS) 标记的嵌入，或者如果进行条件生成（如文本到音频），则可能是条件信息（如文本嵌入）的表示。
2.  **生成循环:**
    *   将当前输入序列送入 Mamba 模型。
    *   获取模型在 **最后一个时间步** 输出的 logits，形状为 `(B, 1, Q, C)`。
    *   **采样:** 对于每个量化器 `q`，根据其对应的 logits `(B, 1, 1, C)` 选择 **下一个** 码本索引 `next_s_q`。
        *   **Greedy:** 使用 `argmax` 选择概率最高的索引。
        *   **Sampling:** 使用更高级的采样策略（如 nucleus sampling, top-k sampling, temperature scaling）从概率分布中采样，以增加生成的多样性。
    *   **组合索引:** 将当前时间步生成的 `Q` 个索引 `[next_s_0, next_s_1, ..., next_s_{Q-1}]` 组合起来。
    *   **准备下一输入:** 将这组新生成的索引通过 **与训练时相同的嵌入层和组合方法** 转换为下一个时间步的输入嵌入 `x_next`。
    *   **更新序列:** 将 `x_next` 附加到 Mamba 的输入序列末尾。同时，将生成的 `Q` 个索引 `[next_s_0, ..., next_s_{Q-1}]` 保存到一个列表中。
    *   **重复:** 重复这个过程，直到生成了所需长度的序列或模型生成了一个特殊的 "end-of-sequence" (EOS) 标记。
3.  **输出编码:** 循环结束后，你会得到一个生成的码本索引序列 `s_generated`，形状为 `(B, generated_length, Q)`。
4.  **DAC 解码:**
    *   将 `s_generated` 的形状调整回 DAC 解码器期望的 `(B, Q, generated_length)`：`s_for_decode = s_generated.permute(0, 2, 1)`。
    *   将 `s_for_decode` 输入 DAC 模型的 `decode(s=...)` 方法，得到最终生成的音频波形。

**总结:**

*   **训练:** Mamba 以 `s` 的嵌入向量之和作为输入，学习预测下一时间步的 `s`（每个量化器一个索引），使用交叉熵损失。
*   **推理:** Mamba 自回归地生成 `s` 的索引序列，每次生成一个时间步的 `Q` 个索引，并将它们转换为嵌入作为下一步的输入。最后将生成的完整 `s` 序列送入 DAC 解码器。

这种方法将音频生成的挑战转化为了一个结构化的离散序列预测问题，Mamba 在处理长序列依赖关系方面表现出色，因此很适合这类任务。